{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6WMTwUViB6Ql"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/cleaned_features.csv\")\n",
        "word_columns = [\"subject\", \"session\"]\n",
        "\n",
        "# Ensure they exist in the dataframe\n",
        "word_columns = [col for col in word_columns if col in df.columns]\n",
        "\n",
        "# Separate word columns and numeric features\n",
        "df_words = df[word_columns]  # Keep subject and session\n",
        "df_features = df.drop(columns=word_columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvA22xqsCjon",
        "outputId": "00df3b58-92ed-4a3d-8622-0a95078ee375"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "0    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "1    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "2    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "3    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "4    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "...            ...           ...           ...       ...           ...   \n",
            "1381  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1382  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1383  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1384  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1385  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "0      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "1      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "2      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "3      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "4      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "...             ...           ...           ...           ...       ...  ...   \n",
            "1381   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1382   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1383   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1384   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1385   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "\n",
            "      ch23_entropy  ch24_entropy  ch25_entropy  ch26_entropy  ch27_entropy  \\\n",
            "0         1.503174      1.458431      1.270688      1.301796      1.394254   \n",
            "1         1.503174      1.458431      1.270688      1.301796      1.394254   \n",
            "2         1.503174      1.458431      1.270688      1.301796      1.394254   \n",
            "3         1.503174      1.458431      1.270688      1.301796      1.394254   \n",
            "4         1.503174      1.458431      1.270688      1.301796      1.394254   \n",
            "...            ...           ...           ...           ...           ...   \n",
            "1381      1.055390      1.503678      1.420021      1.420620      1.229805   \n",
            "1382      1.055390      1.503678      1.420021      1.420620      1.229805   \n",
            "1383      1.055390      1.503678      1.420021      1.420620      1.229805   \n",
            "1384      1.055390      1.503678      1.420021      1.420620      1.229805   \n",
            "1385           NaN           NaN           NaN           NaN           NaN   \n",
            "\n",
            "      ch28_entropy  ch29_entropy  ch30_entropy  ch31_entropy  epoch  \n",
            "0         1.373021      1.308473      1.526453      1.312272    0.0  \n",
            "1         1.373021      1.308473      1.526453      1.312272    1.0  \n",
            "2         1.373021      1.308473      1.526453      1.312272    2.0  \n",
            "3         1.373021      1.308473      1.526453      1.312272    3.0  \n",
            "4         1.373021      1.308473      1.526453      1.312272    4.0  \n",
            "...            ...           ...           ...           ...    ...  \n",
            "1381      1.383978      1.433382      1.110241      1.393377   32.0  \n",
            "1382      1.383978      1.433382      1.110241      1.393377   33.0  \n",
            "1383      1.383978      1.433382      1.110241      1.393377   34.0  \n",
            "1384      1.383978      1.433382      1.110241      1.393377   35.0  \n",
            "1385           NaN           NaN           NaN           NaN    NaN  \n",
            "\n",
            "[1386 rows x 385 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "t623mN6hCsvp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_features.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2s0bm3VDAWO",
        "outputId": "8c7c7925-587c-4ab6-afcb-b6bf9580820f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ch0_mean', 'ch0_std', 'ch0_var', 'ch0_skew', 'ch0_kurtosis', 'ch0_peak2peak', 'ch1_mean', 'ch1_std', 'ch1_var', 'ch1_skew', 'ch1_kurtosis', 'ch1_peak2peak', 'ch2_mean', 'ch2_std', 'ch2_var', 'ch2_skew', 'ch2_kurtosis', 'ch2_peak2peak', 'ch3_mean', 'ch3_std', 'ch3_var', 'ch3_skew', 'ch3_kurtosis', 'ch3_peak2peak', 'ch4_mean', 'ch4_std', 'ch4_var', 'ch4_skew', 'ch4_kurtosis', 'ch4_peak2peak', 'ch5_mean', 'ch5_std', 'ch5_var', 'ch5_skew', 'ch5_kurtosis', 'ch5_peak2peak', 'ch6_mean', 'ch6_std', 'ch6_var', 'ch6_skew', 'ch6_kurtosis', 'ch6_peak2peak', 'ch7_mean', 'ch7_std', 'ch7_var', 'ch7_skew', 'ch7_kurtosis', 'ch7_peak2peak', 'ch8_mean', 'ch8_std', 'ch8_var', 'ch8_skew', 'ch8_kurtosis', 'ch8_peak2peak', 'ch9_mean', 'ch9_std', 'ch9_var', 'ch9_skew', 'ch9_kurtosis', 'ch9_peak2peak', 'ch10_mean', 'ch10_std', 'ch10_var', 'ch10_skew', 'ch10_kurtosis', 'ch10_peak2peak', 'ch11_mean', 'ch11_std', 'ch11_var', 'ch11_skew', 'ch11_kurtosis', 'ch11_peak2peak', 'ch12_mean', 'ch12_std', 'ch12_var', 'ch12_skew', 'ch12_kurtosis', 'ch12_peak2peak', 'ch13_mean', 'ch13_std', 'ch13_var', 'ch13_skew', 'ch13_kurtosis', 'ch13_peak2peak', 'ch14_mean', 'ch14_std', 'ch14_var', 'ch14_skew', 'ch14_kurtosis', 'ch14_peak2peak', 'ch15_mean', 'ch15_std', 'ch15_var', 'ch15_skew', 'ch15_kurtosis', 'ch15_peak2peak', 'ch16_mean', 'ch16_std', 'ch16_var', 'ch16_skew', 'ch16_kurtosis', 'ch16_peak2peak', 'ch17_mean', 'ch17_std', 'ch17_var', 'ch17_skew', 'ch17_kurtosis', 'ch17_peak2peak', 'ch18_mean', 'ch18_std', 'ch18_var', 'ch18_skew', 'ch18_kurtosis', 'ch18_peak2peak', 'ch19_mean', 'ch19_std', 'ch19_var', 'ch19_skew', 'ch19_kurtosis', 'ch19_peak2peak', 'ch20_mean', 'ch20_std', 'ch20_var', 'ch20_skew', 'ch20_kurtosis', 'ch20_peak2peak', 'ch21_mean', 'ch21_std', 'ch21_var', 'ch21_skew', 'ch21_kurtosis', 'ch21_peak2peak', 'ch22_mean', 'ch22_std', 'ch22_var', 'ch22_skew', 'ch22_kurtosis', 'ch22_peak2peak', 'ch23_mean', 'ch23_std', 'ch23_var', 'ch23_skew', 'ch23_kurtosis', 'ch23_peak2peak', 'ch24_mean', 'ch24_std', 'ch24_var', 'ch24_skew', 'ch24_kurtosis', 'ch24_peak2peak', 'ch25_mean', 'ch25_std', 'ch25_var', 'ch25_skew', 'ch25_kurtosis', 'ch25_peak2peak', 'ch26_mean', 'ch26_std', 'ch26_var', 'ch26_skew', 'ch26_kurtosis', 'ch26_peak2peak', 'ch27_mean', 'ch27_std', 'ch27_var', 'ch27_skew', 'ch27_kurtosis', 'ch27_peak2peak', 'ch28_mean', 'ch28_std', 'ch28_var', 'ch28_skew', 'ch28_kurtosis', 'ch28_peak2peak', 'ch29_mean', 'ch29_std', 'ch29_var', 'ch29_skew', 'ch29_kurtosis', 'ch29_peak2peak', 'ch30_mean', 'ch30_std', 'ch30_var', 'ch30_skew', 'ch30_kurtosis', 'ch30_peak2peak', 'ch31_mean', 'ch31_std', 'ch31_var', 'ch31_skew', 'ch31_kurtosis', 'ch31_peak2peak', 'ch0_delta_power', 'ch0_theta_power', 'ch0_alpha_power', 'ch0_beta_power', 'ch0_gamma_power', 'ch1_delta_power', 'ch1_theta_power', 'ch1_alpha_power', 'ch1_beta_power', 'ch1_gamma_power', 'ch2_delta_power', 'ch2_theta_power', 'ch2_alpha_power', 'ch2_beta_power', 'ch2_gamma_power', 'ch3_delta_power', 'ch3_theta_power', 'ch3_alpha_power', 'ch3_beta_power', 'ch3_gamma_power', 'ch4_delta_power', 'ch4_theta_power', 'ch4_alpha_power', 'ch4_beta_power', 'ch4_gamma_power', 'ch5_delta_power', 'ch5_theta_power', 'ch5_alpha_power', 'ch5_beta_power', 'ch5_gamma_power', 'ch6_delta_power', 'ch6_theta_power', 'ch6_alpha_power', 'ch6_beta_power', 'ch6_gamma_power', 'ch7_delta_power', 'ch7_theta_power', 'ch7_alpha_power', 'ch7_beta_power', 'ch7_gamma_power', 'ch8_delta_power', 'ch8_theta_power', 'ch8_alpha_power', 'ch8_beta_power', 'ch8_gamma_power', 'ch9_delta_power', 'ch9_theta_power', 'ch9_alpha_power', 'ch9_beta_power', 'ch9_gamma_power', 'ch10_delta_power', 'ch10_theta_power', 'ch10_alpha_power', 'ch10_beta_power', 'ch10_gamma_power', 'ch11_delta_power', 'ch11_theta_power', 'ch11_alpha_power', 'ch11_beta_power', 'ch11_gamma_power', 'ch12_delta_power', 'ch12_theta_power', 'ch12_alpha_power', 'ch12_beta_power', 'ch12_gamma_power', 'ch13_delta_power', 'ch13_theta_power', 'ch13_alpha_power', 'ch13_beta_power', 'ch13_gamma_power', 'ch14_delta_power', 'ch14_theta_power', 'ch14_alpha_power', 'ch14_beta_power', 'ch14_gamma_power', 'ch15_delta_power', 'ch15_theta_power', 'ch15_alpha_power', 'ch15_beta_power', 'ch15_gamma_power', 'ch16_delta_power', 'ch16_theta_power', 'ch16_alpha_power', 'ch16_beta_power', 'ch16_gamma_power', 'ch17_delta_power', 'ch17_theta_power', 'ch17_alpha_power', 'ch17_beta_power', 'ch17_gamma_power', 'ch18_delta_power', 'ch18_theta_power', 'ch18_alpha_power', 'ch18_beta_power', 'ch18_gamma_power', 'ch19_delta_power', 'ch19_theta_power', 'ch19_alpha_power', 'ch19_beta_power', 'ch19_gamma_power', 'ch20_delta_power', 'ch20_theta_power', 'ch20_alpha_power', 'ch20_beta_power', 'ch20_gamma_power', 'ch21_delta_power', 'ch21_theta_power', 'ch21_alpha_power', 'ch21_beta_power', 'ch21_gamma_power', 'ch22_delta_power', 'ch22_theta_power', 'ch22_alpha_power', 'ch22_beta_power', 'ch22_gamma_power', 'ch23_delta_power', 'ch23_theta_power', 'ch23_alpha_power', 'ch23_beta_power', 'ch23_gamma_power', 'ch24_delta_power', 'ch24_theta_power', 'ch24_alpha_power', 'ch24_beta_power', 'ch24_gamma_power', 'ch25_delta_power', 'ch25_theta_power', 'ch25_alpha_power', 'ch25_beta_power', 'ch25_gamma_power', 'ch26_delta_power', 'ch26_theta_power', 'ch26_alpha_power', 'ch26_beta_power', 'ch26_gamma_power', 'ch27_delta_power', 'ch27_theta_power', 'ch27_alpha_power', 'ch27_beta_power', 'ch27_gamma_power', 'ch28_delta_power', 'ch28_theta_power', 'ch28_alpha_power', 'ch28_beta_power', 'ch28_gamma_power', 'ch29_delta_power', 'ch29_theta_power', 'ch29_alpha_power', 'ch29_beta_power', 'ch29_gamma_power', 'ch30_delta_power', 'ch30_theta_power', 'ch30_alpha_power', 'ch30_beta_power', 'ch30_gamma_power', 'ch31_delta_power', 'ch31_theta_power', 'ch31_alpha_power', 'ch31_beta_power', 'ch31_gamma_power', 'ch0_entropy', 'ch1_entropy', 'ch2_entropy', 'ch3_entropy', 'ch4_entropy', 'ch5_entropy', 'ch6_entropy', 'ch7_entropy', 'ch8_entropy', 'ch9_entropy', 'ch10_entropy', 'ch11_entropy', 'ch12_entropy', 'ch13_entropy', 'ch14_entropy', 'ch15_entropy', 'ch16_entropy', 'ch17_entropy', 'ch18_entropy', 'ch19_entropy', 'ch20_entropy', 'ch21_entropy', 'ch22_entropy', 'ch23_entropy', 'ch24_entropy', 'ch25_entropy', 'ch26_entropy', 'ch27_entropy', 'ch28_entropy', 'ch29_entropy', 'ch30_entropy', 'ch31_entropy', 'epoch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.read_csv(\"/content/extracted_features (1).csv\")\n",
        "print(df2.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1cwuf2NDUH8",
        "outputId": "3c4589e2-e25f-408e-b8fe-c9ce1285fbb2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ch0_mean', 'ch0_std', 'ch0_var', 'ch0_skew', 'ch0_kurtosis', 'ch0_peak2peak', 'ch1_mean', 'ch1_std', 'ch1_var', 'ch1_skew', 'ch1_kurtosis', 'ch1_peak2peak', 'ch2_mean', 'ch2_std', 'ch2_var', 'ch2_skew', 'ch2_kurtosis', 'ch2_peak2peak', 'ch3_mean', 'ch3_std', 'ch3_var', 'ch3_skew', 'ch3_kurtosis', 'ch3_peak2peak', 'ch4_mean', 'ch4_std', 'ch4_var', 'ch4_skew', 'ch4_kurtosis', 'ch4_peak2peak', 'ch5_mean', 'ch5_std', 'ch5_var', 'ch5_skew', 'ch5_kurtosis', 'ch5_peak2peak', 'ch6_mean', 'ch6_std', 'ch6_var', 'ch6_skew', 'ch6_kurtosis', 'ch6_peak2peak', 'ch7_mean', 'ch7_std', 'ch7_var', 'ch7_skew', 'ch7_kurtosis', 'ch7_peak2peak', 'ch8_mean', 'ch8_std', 'ch8_var', 'ch8_skew', 'ch8_kurtosis', 'ch8_peak2peak', 'ch9_mean', 'ch9_std', 'ch9_var', 'ch9_skew', 'ch9_kurtosis', 'ch9_peak2peak', 'ch10_mean', 'ch10_std', 'ch10_var', 'ch10_skew', 'ch10_kurtosis', 'ch10_peak2peak', 'ch11_mean', 'ch11_std', 'ch11_var', 'ch11_skew', 'ch11_kurtosis', 'ch11_peak2peak', 'ch12_mean', 'ch12_std', 'ch12_var', 'ch12_skew', 'ch12_kurtosis', 'ch12_peak2peak', 'ch13_mean', 'ch13_std', 'ch13_var', 'ch13_skew', 'ch13_kurtosis', 'ch13_peak2peak', 'ch14_mean', 'ch14_std', 'ch14_var', 'ch14_skew', 'ch14_kurtosis', 'ch14_peak2peak', 'ch15_mean', 'ch15_std', 'ch15_var', 'ch15_skew', 'ch15_kurtosis', 'ch15_peak2peak', 'ch16_mean', 'ch16_std', 'ch16_var', 'ch16_skew', 'ch16_kurtosis', 'ch16_peak2peak', 'ch17_mean', 'ch17_std', 'ch17_var', 'ch17_skew', 'ch17_kurtosis', 'ch17_peak2peak', 'ch18_mean', 'ch18_std', 'ch18_var', 'ch18_skew', 'ch18_kurtosis', 'ch18_peak2peak', 'ch19_mean', 'ch19_std', 'ch19_var', 'ch19_skew', 'ch19_kurtosis', 'ch19_peak2peak', 'ch20_mean', 'ch20_std', 'ch20_var', 'ch20_skew', 'ch20_kurtosis', 'ch20_peak2peak', 'ch21_mean', 'ch21_std', 'ch21_var', 'ch21_skew', 'ch21_kurtosis', 'ch21_peak2peak', 'ch22_mean', 'ch22_std', 'ch22_var', 'ch22_skew', 'ch22_kurtosis', 'ch22_peak2peak', 'ch23_mean', 'ch23_std', 'ch23_var', 'ch23_skew', 'ch23_kurtosis', 'ch23_peak2peak', 'ch24_mean', 'ch24_std', 'ch24_var', 'ch24_skew', 'ch24_kurtosis', 'ch24_peak2peak', 'ch25_mean', 'ch25_std', 'ch25_var', 'ch25_skew', 'ch25_kurtosis', 'ch25_peak2peak', 'ch26_mean', 'ch26_std', 'ch26_var', 'ch26_skew', 'ch26_kurtosis', 'ch26_peak2peak', 'ch27_mean', 'ch27_std', 'ch27_var', 'ch27_skew', 'ch27_kurtosis', 'ch27_peak2peak', 'ch28_mean', 'ch28_std', 'ch28_var', 'ch28_skew', 'ch28_kurtosis', 'ch28_peak2peak', 'ch29_mean', 'ch29_std', 'ch29_var', 'ch29_skew', 'ch29_kurtosis', 'ch29_peak2peak', 'ch30_mean', 'ch30_std', 'ch30_var', 'ch30_skew', 'ch30_kurtosis', 'ch30_peak2peak', 'ch31_mean', 'ch31_std', 'ch31_var', 'ch31_skew', 'ch31_kurtosis', 'ch31_peak2peak', 'ch0_delta_power', 'ch0_theta_power', 'ch0_alpha_power', 'ch0_beta_power', 'ch0_gamma_power', 'ch1_delta_power', 'ch1_theta_power', 'ch1_alpha_power', 'ch1_beta_power', 'ch1_gamma_power', 'ch2_delta_power', 'ch2_theta_power', 'ch2_alpha_power', 'ch2_beta_power', 'ch2_gamma_power', 'ch3_delta_power', 'ch3_theta_power', 'ch3_alpha_power', 'ch3_beta_power', 'ch3_gamma_power', 'ch4_delta_power', 'ch4_theta_power', 'ch4_alpha_power', 'ch4_beta_power', 'ch4_gamma_power', 'ch5_delta_power', 'ch5_theta_power', 'ch5_alpha_power', 'ch5_beta_power', 'ch5_gamma_power', 'ch6_delta_power', 'ch6_theta_power', 'ch6_alpha_power', 'ch6_beta_power', 'ch6_gamma_power', 'ch7_delta_power', 'ch7_theta_power', 'ch7_alpha_power', 'ch7_beta_power', 'ch7_gamma_power', 'ch8_delta_power', 'ch8_theta_power', 'ch8_alpha_power', 'ch8_beta_power', 'ch8_gamma_power', 'ch9_delta_power', 'ch9_theta_power', 'ch9_alpha_power', 'ch9_beta_power', 'ch9_gamma_power', 'ch10_delta_power', 'ch10_theta_power', 'ch10_alpha_power', 'ch10_beta_power', 'ch10_gamma_power', 'ch11_delta_power', 'ch11_theta_power', 'ch11_alpha_power', 'ch11_beta_power', 'ch11_gamma_power', 'ch12_delta_power', 'ch12_theta_power', 'ch12_alpha_power', 'ch12_beta_power', 'ch12_gamma_power', 'ch13_delta_power', 'ch13_theta_power', 'ch13_alpha_power', 'ch13_beta_power', 'ch13_gamma_power', 'ch14_delta_power', 'ch14_theta_power', 'ch14_alpha_power', 'ch14_beta_power', 'ch14_gamma_power', 'ch15_delta_power', 'ch15_theta_power', 'ch15_alpha_power', 'ch15_beta_power', 'ch15_gamma_power', 'ch16_delta_power', 'ch16_theta_power', 'ch16_alpha_power', 'ch16_beta_power', 'ch16_gamma_power', 'ch17_delta_power', 'ch17_theta_power', 'ch17_alpha_power', 'ch17_beta_power', 'ch17_gamma_power', 'ch18_delta_power', 'ch18_theta_power', 'ch18_alpha_power', 'ch18_beta_power', 'ch18_gamma_power', 'ch19_delta_power', 'ch19_theta_power', 'ch19_alpha_power', 'ch19_beta_power', 'ch19_gamma_power', 'ch20_delta_power', 'ch20_theta_power', 'ch20_alpha_power', 'ch20_beta_power', 'ch20_gamma_power', 'ch21_delta_power', 'ch21_theta_power', 'ch21_alpha_power', 'ch21_beta_power', 'ch21_gamma_power', 'ch22_delta_power', 'ch22_theta_power', 'ch22_alpha_power', 'ch22_beta_power', 'ch22_gamma_power', 'ch23_delta_power', 'ch23_theta_power', 'ch23_alpha_power', 'ch23_beta_power', 'ch23_gamma_power', 'ch24_delta_power', 'ch24_theta_power', 'ch24_alpha_power', 'ch24_beta_power', 'ch24_gamma_power', 'ch25_delta_power', 'ch25_theta_power', 'ch25_alpha_power', 'ch25_beta_power', 'ch25_gamma_power', 'ch26_delta_power', 'ch26_theta_power', 'ch26_alpha_power', 'ch26_beta_power', 'ch26_gamma_power', 'ch27_delta_power', 'ch27_theta_power', 'ch27_alpha_power', 'ch27_beta_power', 'ch27_gamma_power', 'ch28_delta_power', 'ch28_theta_power', 'ch28_alpha_power', 'ch28_beta_power', 'ch28_gamma_power', 'ch29_delta_power', 'ch29_theta_power', 'ch29_alpha_power', 'ch29_beta_power', 'ch29_gamma_power', 'ch30_delta_power', 'ch30_theta_power', 'ch30_alpha_power', 'ch30_beta_power', 'ch30_gamma_power', 'ch31_delta_power', 'ch31_theta_power', 'ch31_alpha_power', 'ch31_beta_power', 'ch31_gamma_power', 'ch0_entropy', 'ch1_entropy', 'ch2_entropy', 'ch3_entropy', 'ch4_entropy', 'ch5_entropy', 'ch6_entropy', 'ch7_entropy', 'ch8_entropy', 'ch9_entropy', 'ch10_entropy', 'ch11_entropy', 'ch12_entropy', 'ch13_entropy', 'ch14_entropy', 'ch15_entropy', 'ch16_entropy', 'ch17_entropy', 'ch18_entropy', 'ch19_entropy', 'ch20_entropy', 'ch21_entropy', 'ch22_entropy', 'ch23_entropy', 'ch24_entropy', 'ch25_entropy', 'ch26_entropy', 'ch27_entropy', 'ch28_entropy', 'ch29_entropy', 'ch30_entropy', 'ch31_entropy', 'subject', 'session', 'epoch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2[\"epoch\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fg7CahMEgsV",
        "outputId": "66863c7f-7538-4830-80e8-a08fc694be83"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         0\n",
            "1         1\n",
            "2         2\n",
            "3         3\n",
            "4         4\n",
            "       ... \n",
            "3591    145\n",
            "3592    146\n",
            "3593    147\n",
            "3594    148\n",
            "3595    149\n",
            "Name: epoch, Length: 3596, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the extracted feature dataset\n",
        "features_path = \"/content/extracted_features (1).csv\"  # Update with actual path\n",
        "df = pd.read_csv(features_path)\n",
        "\n",
        "# Expected trials per session\n",
        "EXPECTED_TRIALS = 150\n",
        "EXCEPTION_CASE = (6, 4)  # (Subject 6, Session 4) has 144 trials\n",
        "\n",
        "# Count trials for each subject-session pair\n",
        "trial_counts = df.groupby(['subject', 'session']).size().reset_index(name='num_trials')\n",
        "\n",
        "# Check for mismatches\n",
        "for _, row in trial_counts.iterrows():\n",
        "    subj, sess, num_trials = row['subject'], row['session'], row['num_trials']\n",
        "    expected = 144 if (subj, sess) == EXCEPTION_CASE else EXPECTED_TRIALS\n",
        "\n",
        "    if num_trials != expected:\n",
        "        print(f\"⚠️ Mismatch for Subject {subj}, Session {sess}: Found {num_trials}, Expected {expected}\")\n",
        "\n",
        "# Display the trial counts\n",
        "print(trial_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4koanNRFNBz",
        "outputId": "08c16a2a-cd2a-45e5-d743-1df494007040"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Mismatch for Subject sub-02, Session ses-01: Found 149, Expected 150\n",
            "⚠️ Mismatch for Subject sub-04, Session ses-01: Found 149, Expected 150\n",
            "⚠️ Mismatch for Subject sub-06, Session ses-03: Found 149, Expected 150\n",
            "⚠️ Mismatch for Subject sub-08, Session ses-02: Found 149, Expected 150\n",
            "   subject session  num_trials\n",
            "0   sub-01  ses-01         150\n",
            "1   sub-01  ses-02         150\n",
            "2   sub-01  ses-03         150\n",
            "3   sub-02  ses-01         149\n",
            "4   sub-02  ses-02         150\n",
            "5   sub-02  ses-03         150\n",
            "6   sub-03  ses-01         150\n",
            "7   sub-03  ses-02         150\n",
            "8   sub-03  ses-03         150\n",
            "9   sub-04  ses-01         149\n",
            "10  sub-04  ses-02         150\n",
            "11  sub-04  ses-03         150\n",
            "12  sub-05  ses-01         150\n",
            "13  sub-05  ses-02         150\n",
            "14  sub-05  ses-03         150\n",
            "15  sub-06  ses-01         150\n",
            "16  sub-06  ses-02         150\n",
            "17  sub-06  ses-03         149\n",
            "18  sub-07  ses-01         150\n",
            "19  sub-07  ses-02         150\n",
            "20  sub-07  ses-03         150\n",
            "21  sub-08  ses-01         150\n",
            "22  sub-08  ses-02         149\n",
            "23  sub-08  ses-03         150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Expected trials per session\n",
        "EXPECTED_TRIALS = 150\n",
        "EXCEPTION_CASE = (6, 4)  # (Subject 6, Session 4) should have 144 trials\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicates = df.duplicated(subset=['subject', 'session'], keep=False)\n",
        "\n",
        "if duplicates.any():\n",
        "    print(f\"⚠️ Warning: Found {duplicates.sum()} duplicate rows!\")\n",
        "    print(df[duplicates].head())\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum().sum()\n",
        "if missing_values > 0:\n",
        "    print(f\"⚠️ Warning: Found {missing_values} missing values!\")\n",
        "\n",
        "# Count unique trials per subject-session\n",
        "trial_counts = df.groupby(['subject', 'session']).size().reset_index(name='num_trials')\n",
        "\n",
        "# Find which rows are missing one trial\n",
        "for _, row in trial_counts.iterrows():\n",
        "    subj, sess, num_trials = row['subject'], row['session'], row['num_trials']\n",
        "    expected = 144 if (subj, sess) == EXCEPTION_CASE else EXPECTED_TRIALS\n",
        "\n",
        "    if num_trials != expected:\n",
        "        print(f\"🚨 Missing trials for Subject {subj}, Session {sess}: Found {num_trials}, Expected {expected}\")\n",
        "        # Show affected rows\n",
        "        print(df[(df['subject'] == subj) & (df['session'] == sess)].head())\n",
        "\n",
        "# Display trial counts summary\n",
        "print(trial_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i9Xy2nyFjpq",
        "outputId": "eb16d7fa-788c-46ed-ca40-81c646933319"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Warning: Found 3596 duplicate rows!\n",
            "       ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "0 -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "1 -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "2 -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "3 -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "4 -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "\n",
            "   ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "0   2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "1   2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "2   2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "3   2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "4   2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "\n",
            "   ch25_entropy  ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  \\\n",
            "0      1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "1      1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "2      1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "3      1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "4      1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "\n",
            "   ch30_entropy  ch31_entropy  subject  session  epoch  \n",
            "0      1.526453      1.312272   sub-01   ses-02      0  \n",
            "1      1.526453      1.312272   sub-01   ses-02      1  \n",
            "2      1.526453      1.312272   sub-01   ses-02      2  \n",
            "3      1.526453      1.312272   sub-01   ses-02      3  \n",
            "4      1.526453      1.312272   sub-01   ses-02      4  \n",
            "\n",
            "[5 rows x 387 columns]\n",
            "🚨 Missing trials for Subject sub-02, Session ses-01: Found 149, Expected 150\n",
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "2248  3.776646e-30  1.193000e-21  1.423250e-42   0.17989      0.020308   \n",
            "2249  3.776646e-30  1.193000e-21  1.423250e-42   0.17989      0.020308   \n",
            "2250  3.776646e-30  1.193000e-21  1.423250e-42   0.17989      0.020308   \n",
            "2251  3.776646e-30  1.193000e-21  1.423250e-42   0.17989      0.020308   \n",
            "2252  3.776646e-30  1.193000e-21  1.423250e-42   0.17989      0.020308   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "2248   7.407919e-21 -1.141232e-30  1.261048e-21  1.590243e-42 -0.086352  ...   \n",
            "2249   7.407919e-21 -1.141232e-30  1.261048e-21  1.590243e-42 -0.086352  ...   \n",
            "2250   7.407919e-21 -1.141232e-30  1.261048e-21  1.590243e-42 -0.086352  ...   \n",
            "2251   7.407919e-21 -1.141232e-30  1.261048e-21  1.590243e-42 -0.086352  ...   \n",
            "2252   7.407919e-21 -1.141232e-30  1.261048e-21  1.590243e-42 -0.086352  ...   \n",
            "\n",
            "      ch25_entropy  ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  \\\n",
            "2248      1.507049      1.483303      1.480381      1.479485      1.255638   \n",
            "2249      1.507049      1.483303      1.480381      1.479485      1.255638   \n",
            "2250      1.507049      1.483303      1.480381      1.479485      1.255638   \n",
            "2251      1.507049      1.483303      1.480381      1.479485      1.255638   \n",
            "2252      1.507049      1.483303      1.480381      1.479485      1.255638   \n",
            "\n",
            "      ch30_entropy  ch31_entropy  subject  session  epoch  \n",
            "2248      1.359331      1.456941   sub-02   ses-01      0  \n",
            "2249      1.359331      1.456941   sub-02   ses-01      1  \n",
            "2250      1.359331      1.456941   sub-02   ses-01      2  \n",
            "2251      1.359331      1.456941   sub-02   ses-01      3  \n",
            "2252      1.359331      1.456941   sub-02   ses-01      4  \n",
            "\n",
            "[5 rows x 387 columns]\n",
            "🚨 Missing trials for Subject sub-04, Session ses-01: Found 149, Expected 150\n",
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "1349  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1350  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1351  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1352  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "1353  2.429671e-30  6.357432e-22  4.041694e-43  0.208561     -0.343213   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "1349   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1350   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1351   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1352   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "1353   3.165310e-21 -1.836230e-31  1.063266e-21  1.130535e-42  0.117896  ...   \n",
            "\n",
            "      ch25_entropy  ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  \\\n",
            "1349      1.420021       1.42062      1.229805      1.383978      1.433382   \n",
            "1350      1.420021       1.42062      1.229805      1.383978      1.433382   \n",
            "1351      1.420021       1.42062      1.229805      1.383978      1.433382   \n",
            "1352      1.420021       1.42062      1.229805      1.383978      1.433382   \n",
            "1353      1.420021       1.42062      1.229805      1.383978      1.433382   \n",
            "\n",
            "      ch30_entropy  ch31_entropy  subject  session  epoch  \n",
            "1349      1.110241      1.393377   sub-04   ses-01      0  \n",
            "1350      1.110241      1.393377   sub-04   ses-01      1  \n",
            "1351      1.110241      1.393377   sub-04   ses-01      2  \n",
            "1352      1.110241      1.393377   sub-04   ses-01      3  \n",
            "1353      1.110241      1.393377   sub-04   ses-01      4  \n",
            "\n",
            "[5 rows x 387 columns]\n",
            "🚨 Missing trials for Subject sub-06, Session ses-03: Found 149, Expected 150\n",
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "3297  6.320376e-30  4.919667e-22  2.420312e-43 -0.147049     -0.539047   \n",
            "3298  6.320376e-30  4.919667e-22  2.420312e-43 -0.147049     -0.539047   \n",
            "3299  6.320376e-30  4.919667e-22  2.420312e-43 -0.147049     -0.539047   \n",
            "3300  6.320376e-30  4.919667e-22  2.420312e-43 -0.147049     -0.539047   \n",
            "3301  6.320376e-30  4.919667e-22  2.420312e-43 -0.147049     -0.539047   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "3297   2.534895e-21  3.122617e-30  3.971901e-22  1.577600e-43  0.445248  ...   \n",
            "3298   2.534895e-21  3.122617e-30  3.971901e-22  1.577600e-43  0.445248  ...   \n",
            "3299   2.534895e-21  3.122617e-30  3.971901e-22  1.577600e-43  0.445248  ...   \n",
            "3300   2.534895e-21  3.122617e-30  3.971901e-22  1.577600e-43  0.445248  ...   \n",
            "3301   2.534895e-21  3.122617e-30  3.971901e-22  1.577600e-43  0.445248  ...   \n",
            "\n",
            "      ch25_entropy  ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  \\\n",
            "3297      1.467584      1.504431      1.486045      1.281089       1.44402   \n",
            "3298      1.467584      1.504431      1.486045      1.281089       1.44402   \n",
            "3299      1.467584      1.504431      1.486045      1.281089       1.44402   \n",
            "3300      1.467584      1.504431      1.486045      1.281089       1.44402   \n",
            "3301      1.467584      1.504431      1.486045      1.281089       1.44402   \n",
            "\n",
            "      ch30_entropy  ch31_entropy  subject  session  epoch  \n",
            "3297      1.532863      1.385619   sub-06   ses-03      0  \n",
            "3298      1.532863      1.385619   sub-06   ses-03      1  \n",
            "3299      1.532863      1.385619   sub-06   ses-03      2  \n",
            "3300      1.532863      1.385619   sub-06   ses-03      3  \n",
            "3301      1.532863      1.385619   sub-06   ses-03      4  \n",
            "\n",
            "[5 rows x 387 columns]\n",
            "🚨 Missing trials for Subject sub-08, Session ses-02: Found 149, Expected 150\n",
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "1200 -1.193800e-30  6.715591e-23  4.509916e-45  0.257311      0.162899   \n",
            "1201 -1.193800e-30  6.715591e-23  4.509916e-45  0.257311      0.162899   \n",
            "1202 -1.193800e-30  6.715591e-23  4.509916e-45  0.257311      0.162899   \n",
            "1203 -1.193800e-30  6.715591e-23  4.509916e-45  0.257311      0.162899   \n",
            "1204 -1.193800e-30  6.715591e-23  4.509916e-45  0.257311      0.162899   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "1200   4.483319e-22  4.292104e-31  4.776623e-23  2.281613e-45  0.172354  ...   \n",
            "1201   4.483319e-22  4.292104e-31  4.776623e-23  2.281613e-45  0.172354  ...   \n",
            "1202   4.483319e-22  4.292104e-31  4.776623e-23  2.281613e-45  0.172354  ...   \n",
            "1203   4.483319e-22  4.292104e-31  4.776623e-23  2.281613e-45  0.172354  ...   \n",
            "1204   4.483319e-22  4.292104e-31  4.776623e-23  2.281613e-45  0.172354  ...   \n",
            "\n",
            "      ch25_entropy  ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  \\\n",
            "1200      1.214061      1.405673      1.228414      1.465961      1.262829   \n",
            "1201      1.214061      1.405673      1.228414      1.465961      1.262829   \n",
            "1202      1.214061      1.405673      1.228414      1.465961      1.262829   \n",
            "1203      1.214061      1.405673      1.228414      1.465961      1.262829   \n",
            "1204      1.214061      1.405673      1.228414      1.465961      1.262829   \n",
            "\n",
            "      ch30_entropy  ch31_entropy  subject  session  epoch  \n",
            "1200      1.344288      1.243329   sub-08   ses-02      0  \n",
            "1201      1.344288      1.243329   sub-08   ses-02      1  \n",
            "1202      1.344288      1.243329   sub-08   ses-02      2  \n",
            "1203      1.344288      1.243329   sub-08   ses-02      3  \n",
            "1204      1.344288      1.243329   sub-08   ses-02      4  \n",
            "\n",
            "[5 rows x 387 columns]\n",
            "   subject session  num_trials\n",
            "0   sub-01  ses-01         150\n",
            "1   sub-01  ses-02         150\n",
            "2   sub-01  ses-03         150\n",
            "3   sub-02  ses-01         149\n",
            "4   sub-02  ses-02         150\n",
            "5   sub-02  ses-03         150\n",
            "6   sub-03  ses-01         150\n",
            "7   sub-03  ses-02         150\n",
            "8   sub-03  ses-03         150\n",
            "9   sub-04  ses-01         149\n",
            "10  sub-04  ses-02         150\n",
            "11  sub-04  ses-03         150\n",
            "12  sub-05  ses-01         150\n",
            "13  sub-05  ses-02         150\n",
            "14  sub-05  ses-03         150\n",
            "15  sub-06  ses-01         150\n",
            "16  sub-06  ses-02         150\n",
            "17  sub-06  ses-03         149\n",
            "18  sub-07  ses-01         150\n",
            "19  sub-07  ses-02         150\n",
            "20  sub-07  ses-03         150\n",
            "21  sub-08  ses-01         150\n",
            "22  sub-08  ses-02         149\n",
            "23  sub-08  ses-03         150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_missing_trials(df, subject, session):\n",
        "    \"\"\"Find missing trial numbers for a given subject and session.\"\"\"\n",
        "    subset = df[(df['subject'] == subject) & (df['session'] == session)]\n",
        "    expected_trials = set(range(150))  # Expected trials: 0 to 149\n",
        "    actual_trials = set(subset['epoch'].unique())\n",
        "\n",
        "    missing_trials = expected_trials - actual_trials\n",
        "    return missing_trials\n",
        "\n",
        "# Check missing trials for the affected subjects\n",
        "for subj, sess in [('sub-02', 'ses-01'), ('sub-04', 'ses-01'), ('sub-06', 'ses-03'), ('sub-08', 'ses-02')]:\n",
        "    missing = find_missing_trials(df, subj, sess)\n",
        "    if missing:\n",
        "        print(f\"🚨 Missing trials for {subj}, {sess}: {missing}\")\n",
        "    else:\n",
        "        print(f\"✅ No missing trial numbers detected for {subj}, {sess} (but still 149 trials).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJUKgD9KFxn4",
        "outputId": "0d8e8740-36f8-41aa-c1c5-91c1d8c5fa67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚨 Missing trials for sub-02, ses-01: {149}\n",
            "🚨 Missing trials for sub-04, ses-01: {149}\n",
            "🚨 Missing trials for sub-06, ses-03: {149}\n",
            "🚨 Missing trials for sub-08, ses-02: {149}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the fixed sequence of classes\n",
        "target_classes = ['up', 'down', 'right', 'left', 'select', 'cancel']\n",
        "\n",
        "def assign_labels(df):\n",
        "    df = df.copy()\n",
        "    assigned_targets = []\n",
        "\n",
        "    for (subject, session), group in df.groupby(['subject', 'session']):\n",
        "        num_trials = len(group)\n",
        "\n",
        "        if num_trials not in [149, 150]:  # Unexpected case\n",
        "            raise ValueError(f\"Unexpected trial count {num_trials} for {subject}, {session}\")\n",
        "\n",
        "        # Generate labels for 150 trials\n",
        "        full_labels = np.tile(target_classes, 25)  # Full 150-length sequence\n",
        "\n",
        "        # If trials are missing (149 instead of 150), remove last label\n",
        "        if num_trials == 149:\n",
        "            full_labels = full_labels[:-1]  # Drop the last one\n",
        "\n",
        "        assigned_targets.extend(full_labels[:num_trials])  # Assign exactly as needed\n",
        "\n",
        "    df['target'] = assigned_targets\n",
        "    return df\n",
        "\n",
        "df = assign_labels(df)\n",
        "\n",
        "# Verify correct assignment\n",
        "print(df[['subject', 'session', 'epoch', 'target']].head(30))  # Check first 30 rows\n",
        "print(df['target'].value_counts())  # Ensure balanced classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9WPos1cGfGs",
        "outputId": "88cd630b-c1e4-439c-f311-f7a3fd18aff7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   subject session  epoch  target\n",
            "0   sub-01  ses-02      0      up\n",
            "1   sub-01  ses-02      1    down\n",
            "2   sub-01  ses-02      2   right\n",
            "3   sub-01  ses-02      3    left\n",
            "4   sub-01  ses-02      4  select\n",
            "5   sub-01  ses-02      5  cancel\n",
            "6   sub-01  ses-02      6      up\n",
            "7   sub-01  ses-02      7    down\n",
            "8   sub-01  ses-02      8   right\n",
            "9   sub-01  ses-02      9    left\n",
            "10  sub-01  ses-02     10  select\n",
            "11  sub-01  ses-02     11  cancel\n",
            "12  sub-01  ses-02     12      up\n",
            "13  sub-01  ses-02     13    down\n",
            "14  sub-01  ses-02     14   right\n",
            "15  sub-01  ses-02     15    left\n",
            "16  sub-01  ses-02     16  select\n",
            "17  sub-01  ses-02     17  cancel\n",
            "18  sub-01  ses-02     18      up\n",
            "19  sub-01  ses-02     19    down\n",
            "20  sub-01  ses-02     20   right\n",
            "21  sub-01  ses-02     21    left\n",
            "22  sub-01  ses-02     22  select\n",
            "23  sub-01  ses-02     23  cancel\n",
            "24  sub-01  ses-02     24      up\n",
            "25  sub-01  ses-02     25    down\n",
            "26  sub-01  ses-02     26   right\n",
            "27  sub-01  ses-02     27    left\n",
            "28  sub-01  ses-02     28  select\n",
            "29  sub-01  ses-02     29  cancel\n",
            "target\n",
            "up        600\n",
            "down      600\n",
            "right     600\n",
            "left      600\n",
            "select    600\n",
            "cancel    596\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "god=pd.read_csv(\"/content/extracted_features (1).csv\")"
      ],
      "metadata": {
        "id": "xG7j8L-uGnzd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(god)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kzjUhC7G-iW",
        "outputId": "99c5fa21-eec9-4f22-db2c-c5b073b1e596"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "0    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "1    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "2    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "3    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "4    -4.692517e-30  4.383195e-22  1.921240e-43 -0.165564      0.074883   \n",
            "...            ...           ...           ...       ...           ...   \n",
            "3591 -5.464452e-31  2.382294e-22  5.675327e-44  0.203434     -0.078901   \n",
            "3592 -5.464452e-31  2.382294e-22  5.675327e-44  0.203434     -0.078901   \n",
            "3593 -5.464452e-31  2.382294e-22  5.675327e-44  0.203434     -0.078901   \n",
            "3594 -5.464452e-31  2.382294e-22  5.675327e-44  0.203434     -0.078901   \n",
            "3595 -5.464452e-31  2.382294e-22  5.675327e-44  0.203434     -0.078901   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "0      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "1      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "2      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "3      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "4      2.541448e-21  4.132416e-30  3.358177e-22  1.127735e-43  0.429203  ...   \n",
            "...             ...           ...           ...           ...       ...  ...   \n",
            "3591   1.333341e-21  2.608630e-30  3.731601e-22  1.392484e-43  0.485554  ...   \n",
            "3592   1.333341e-21  2.608630e-30  3.731601e-22  1.392484e-43  0.485554  ...   \n",
            "3593   1.333341e-21  2.608630e-30  3.731601e-22  1.392484e-43  0.485554  ...   \n",
            "3594   1.333341e-21  2.608630e-30  3.731601e-22  1.392484e-43  0.485554  ...   \n",
            "3595   1.333341e-21  2.608630e-30  3.731601e-22  1.392484e-43  0.485554  ...   \n",
            "\n",
            "      ch25_entropy  ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  \\\n",
            "0         1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "1         1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "2         1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "3         1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "4         1.270688      1.301796      1.394254      1.373021      1.308473   \n",
            "...            ...           ...           ...           ...           ...   \n",
            "3591      1.460237      1.367385      1.363108      1.283603      1.373750   \n",
            "3592      1.460237      1.367385      1.363108      1.283603      1.373750   \n",
            "3593      1.460237      1.367385      1.363108      1.283603      1.373750   \n",
            "3594      1.460237      1.367385      1.363108      1.283603      1.373750   \n",
            "3595      1.460237      1.367385      1.363108      1.283603      1.373750   \n",
            "\n",
            "      ch30_entropy  ch31_entropy  subject  session  epoch  \n",
            "0         1.526453      1.312272   sub-01   ses-02      0  \n",
            "1         1.526453      1.312272   sub-01   ses-02      1  \n",
            "2         1.526453      1.312272   sub-01   ses-02      2  \n",
            "3         1.526453      1.312272   sub-01   ses-02      3  \n",
            "4         1.526453      1.312272   sub-01   ses-02      4  \n",
            "...            ...           ...      ...      ...    ...  \n",
            "3591      1.320749      1.554496   sub-08   ses-01    145  \n",
            "3592      1.320749      1.554496   sub-08   ses-01    146  \n",
            "3593      1.320749      1.554496   sub-08   ses-01    147  \n",
            "3594      1.320749      1.554496   sub-08   ses-01    148  \n",
            "3595      1.320749      1.554496   sub-08   ses-01    149  \n",
            "\n",
            "[3596 rows x 387 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Expected trials per session\n",
        "expected_trials = 150\n",
        "expected_trials_subject6_ses4 = 144  # Subject 6, Session 4 special case\n",
        "\n",
        "# Count trials per subject-session\n",
        "trial_counts = god.groupby(['subject', 'session']).size().reset_index(name='num_trials')\n",
        "\n",
        "# Verify each subject-session pair\n",
        "missing_sessions = []\n",
        "incorrect_trials = []\n",
        "\n",
        "for i in range(1, 9):  # Subjects 1-8\n",
        "    for j in range(1, 4):  # Sessions 1-3\n",
        "        subject = f\"sub-{i:02d}\"\n",
        "        session = f\"ses-{j:02d}\"\n",
        "\n",
        "        # Check if the subject-session pair exists\n",
        "        match = trial_counts[(trial_counts['subject'] == subject) & (trial_counts['session'] == session)]\n",
        "\n",
        "        if match.empty:\n",
        "            missing_sessions.append((subject, session))\n",
        "        else:\n",
        "            trial_count = match.iloc[0]['num_trials']\n",
        "            expected = expected_trials\n",
        "\n",
        "            # Special case for subject-06 session-04\n",
        "            if subject == \"sub-06\" and session == \"ses-04\":\n",
        "                expected = expected_trials_subject6_ses4\n",
        "\n",
        "            if trial_count != expected:\n",
        "                incorrect_trials.append((subject, session, trial_count, expected))\n",
        "\n",
        "# Print missing sessions\n",
        "if missing_sessions:\n",
        "    print(\"🚨 Missing subject-session pairs:\")\n",
        "    for sub, ses in missing_sessions:\n",
        "        print(f\"  - {sub}, {ses}\")\n",
        "else:\n",
        "    print(\"✅ All subject-session pairs are present.\")\n",
        "\n",
        "# Print incorrect trial counts\n",
        "if incorrect_trials:\n",
        "    print(\"\\n⚠️ Sessions with incorrect trial counts:\")\n",
        "    for sub, ses, found, expected in incorrect_trials:\n",
        "        print(f\"  - {sub}, {ses}: Found {found}, Expected {expected}\")\n",
        "else:\n",
        "    print(\"✅ All subject-session pairs have correct trial counts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XC9IkTNHP4h",
        "outputId": "a19660b5-4d9d-40df-e90d-943b5012bba4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All subject-session pairs are present.\n",
            "\n",
            "⚠️ Sessions with incorrect trial counts:\n",
            "  - sub-02, ses-01: Found 149, Expected 150\n",
            "  - sub-04, ses-01: Found 149, Expected 150\n",
            "  - sub-06, ses-03: Found 149, Expected 150\n",
            "  - sub-08, ses-02: Found 149, Expected 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subject = \"sub-01\"\n",
        "session = \"ses-01\"\n",
        "\n",
        "match = trial_counts[(trial_counts['subject'] == subject) & (trial_counts['session'] == session)]\n",
        "\n",
        "if match.empty:\n",
        "    print(f\"🚨 {subject}, {session} is MISSING!\")\n",
        "else:\n",
        "    trial_count = match.iloc[0]['num_trials']\n",
        "    print(f\"✅ {subject}, {session} is PRESENT with {trial_count} trials.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNDK6qLjHerA",
        "outputId": "f6e5fd7b-c1f4-43d9-d331-4e41546494bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ sub-01, ses-01 is PRESENT with 150 trials.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sort dataset by subject and session\n",
        "df_sorted = god.sort_values(by=[\"subject\", \"session\", \"epoch\"]).reset_index(drop=True)\n",
        "\n",
        "# Function to generate labels based on trial count\n",
        "def assign_labels(trial_count, subject, session):\n",
        "    base_labels = ['up'] * 25 + ['down'] * 25 + ['right'] * 25 + \\\n",
        "                  ['left'] * 25 + ['select'] * 25 + ['cancel'] * 25\n",
        "\n",
        "    if subject == \"sub-06\" and session == \"ses-04\":  # Handle subject 6 case\n",
        "        base_labels = ['up'] * 24 + ['down'] * 24 + ['right'] * 24 + \\\n",
        "                      ['left'] * 24 + ['select'] * 24 + ['cancel'] * 24\n",
        "\n",
        "    return base_labels[:trial_count]  # Trim if trials are missing\n",
        "\n",
        "# Apply labeling\n",
        "df_sorted[\"target\"] = np.concatenate([\n",
        "    assign_labels(len(group), sub, ses)\n",
        "    for (sub, ses), group in df_sorted.groupby([\"subject\", \"session\"])\n",
        "])\n",
        "\n",
        "# Verification step\n",
        "print(df_sorted[[\"subject\", \"session\", \"epoch\", \"target\"]].head(150))  # Check first few rows\n",
        "\n",
        "# Save the cleaned dataset\n",
        "df_sorted.to_csv(\"final_dataset.csv\", index=False)\n",
        "print(\"✅ Final dataset saved as 'final_dataset.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "UtN6-JKbH2mr",
        "outputId": "237f8de8-0510-4a84-b8be-d5f97d2db81f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    subject session  epoch  target\n",
            "0    sub-01  ses-01      0      up\n",
            "1    sub-01  ses-01      1      up\n",
            "2    sub-01  ses-01      2      up\n",
            "3    sub-01  ses-01      3      up\n",
            "4    sub-01  ses-01      4      up\n",
            "..      ...     ...    ...     ...\n",
            "145  sub-01  ses-01    145  cancel\n",
            "146  sub-01  ses-01    146  cancel\n",
            "147  sub-01  ses-01    147  cancel\n",
            "148  sub-01  ses-01    148  cancel\n",
            "149  sub-01  ses-01    149  cancel\n",
            "\n",
            "[150 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-84666937f313>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Save the cleaned dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final_dataset.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Final dataset saved as 'final_dataset.csv'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m             )\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_column_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     ) -> Self:\n\u001b[1;32m   1409\u001b[0m         \u001b[0;31m# helper used by to_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m         mgr = self._mgr.get_values_for_csv(\n\u001b[0m\u001b[1;32m   1411\u001b[0m             \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0mformatting\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;34m\"get_values_for_csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mna_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    778\u001b[0m     ) -> Block:\n\u001b[1;32m    779\u001b[0m         \u001b[0;34m\"\"\"convert to our native types format\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         result = get_values_for_csv(\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mna_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_values_for_csv\u001b[0;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[1;32m   7832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7833\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7834\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7835\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7836\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNSKveo-H9Yn",
        "outputId": "cafc2567-0f93-400e-a317-c8132b24ca93"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ch0_mean       ch0_std       ch0_var  ch0_skew  ch0_kurtosis  \\\n",
            "0    -1.365400e-34  2.253221e-26  5.077004e-52  0.305004     -0.156780   \n",
            "1    -1.365400e-34  2.253221e-26  5.077004e-52  0.305004     -0.156780   \n",
            "2    -1.365400e-34  2.253221e-26  5.077004e-52  0.305004     -0.156780   \n",
            "3    -1.365400e-34  2.253221e-26  5.077004e-52  0.305004     -0.156780   \n",
            "4    -1.365400e-34  2.253221e-26  5.077004e-52  0.305004     -0.156780   \n",
            "...            ...           ...           ...       ...           ...   \n",
            "3591  3.077641e-31  3.069497e-22  9.421811e-44 -0.374264     -0.397671   \n",
            "3592  3.077641e-31  3.069497e-22  9.421811e-44 -0.374264     -0.397671   \n",
            "3593  3.077641e-31  3.069497e-22  9.421811e-44 -0.374264     -0.397671   \n",
            "3594  3.077641e-31  3.069497e-22  9.421811e-44 -0.374264     -0.397671   \n",
            "3595  3.077641e-31  3.069497e-22  9.421811e-44 -0.374264     -0.397671   \n",
            "\n",
            "      ch0_peak2peak      ch1_mean       ch1_std       ch1_var  ch1_skew  ...  \\\n",
            "0      1.254107e-25  4.032866e-35  2.891186e-27  8.358956e-54  0.057327  ...   \n",
            "1      1.254107e-25  4.032866e-35  2.891186e-27  8.358956e-54  0.057327  ...   \n",
            "2      1.254107e-25  4.032866e-35  2.891186e-27  8.358956e-54  0.057327  ...   \n",
            "3      1.254107e-25  4.032866e-35  2.891186e-27  8.358956e-54  0.057327  ...   \n",
            "4      1.254107e-25  4.032866e-35  2.891186e-27  8.358956e-54  0.057327  ...   \n",
            "...             ...           ...           ...           ...       ...  ...   \n",
            "3591   1.544879e-21 -9.638157e-30  5.416355e-22  2.933690e-43 -0.216024  ...   \n",
            "3592   1.544879e-21 -9.638157e-30  5.416355e-22  2.933690e-43 -0.216024  ...   \n",
            "3593   1.544879e-21 -9.638157e-30  5.416355e-22  2.933690e-43 -0.216024  ...   \n",
            "3594   1.544879e-21 -9.638157e-30  5.416355e-22  2.933690e-43 -0.216024  ...   \n",
            "3595   1.544879e-21 -9.638157e-30  5.416355e-22  2.933690e-43 -0.216024  ...   \n",
            "\n",
            "      ch26_entropy  ch27_entropy  ch28_entropy  ch29_entropy  ch30_entropy  \\\n",
            "0         1.458482      1.352584      1.414608      1.461746      1.444946   \n",
            "1         1.458482      1.352584      1.414608      1.461746      1.444946   \n",
            "2         1.458482      1.352584      1.414608      1.461746      1.444946   \n",
            "3         1.458482      1.352584      1.414608      1.461746      1.444946   \n",
            "4         1.458482      1.352584      1.414608      1.461746      1.444946   \n",
            "...            ...           ...           ...           ...           ...   \n",
            "3591      1.399430      1.262726      1.129097      1.308301      1.464554   \n",
            "3592      1.399430      1.262726      1.129097      1.308301      1.464554   \n",
            "3593      1.399430      1.262726      1.129097      1.308301      1.464554   \n",
            "3594      1.399430      1.262726      1.129097      1.308301      1.464554   \n",
            "3595      1.399430      1.262726      1.129097      1.308301      1.464554   \n",
            "\n",
            "      ch31_entropy  subject  session  epoch  target  \n",
            "0         1.488037   sub-01   ses-01      0      up  \n",
            "1         1.488037   sub-01   ses-01      1      up  \n",
            "2         1.488037   sub-01   ses-01      2      up  \n",
            "3         1.488037   sub-01   ses-01      3      up  \n",
            "4         1.488037   sub-01   ses-01      4      up  \n",
            "...            ...      ...      ...    ...     ...  \n",
            "3591      1.081780   sub-08   ses-03    145  cancel  \n",
            "3592      1.081780   sub-08   ses-03    146  cancel  \n",
            "3593      1.081780   sub-08   ses-03    147  cancel  \n",
            "3594      1.081780   sub-08   ses-03    148  cancel  \n",
            "3595      1.081780   sub-08   ses-03    149  cancel  \n",
            "\n",
            "[3596 rows x 388 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "\n",
        "# Drop non-numeric features\n",
        "X = df_sorted.drop(columns=[\"subject\", \"session\", \"target\"])  # Keep only numeric features\n",
        "y = df_sorted[\"target\"]  # Target variable\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train Logistic Regression model on full data\n",
        "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial', random_state=42)\n",
        "clf.fit(X_scaled, y)\n",
        "\n",
        "print(\"✅ Logistic Regression model trained on the full dataset!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImxCt_9wIsIG",
        "outputId": "2fb1b3d9-0bc7-4e06-dcc2-5ed93ea3d70b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Logistic Regression model trained on the full dataset!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted.to_csv(\"final_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "XVrJxnaBI_Xe"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Extract numeric features and target variable\n",
        "X = df_sorted.drop(columns=[\"subject\", \"session\", \"target\"])  # Remove non-numeric columns\n",
        "y = df_sorted[\"target\"]\n",
        "\n",
        "# Perform cross-validation to get accuracy scores\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "cv_scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Train on full dataset\n",
        "logreg.fit(X, y)\n",
        "\n",
        "# Predict on the same dataset\n",
        "y_pred = logreg.predict(X)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"✅ Cross-Validation Accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
        "print(\"\\n📊 Classification Report:\\n\", classification_report(y, y_pred))\n",
        "print(\"\\n📉 Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SB1sRbEJm6v",
        "outputId": "0efc5cf3-8c50-4095-ddd5-46f7842cc80d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cross-Validation Accuracy: 0.9497 ± 0.0177\n",
            "\n",
            "📊 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      cancel       0.99      1.00      1.00       596\n",
            "        down       0.99      0.99      0.99       600\n",
            "        left       0.99      0.99      0.99       600\n",
            "       right       0.99      0.98      0.98       600\n",
            "      select       0.99      0.99      0.99       600\n",
            "          up       0.99      0.99      0.99       600\n",
            "\n",
            "    accuracy                           0.99      3596\n",
            "   macro avg       0.99      0.99      0.99      3596\n",
            "weighted avg       0.99      0.99      0.99      3596\n",
            "\n",
            "\n",
            "📉 Confusion Matrix:\n",
            " [[594   0   0   0   2   0]\n",
            " [  0 592   0   5   0   3]\n",
            " [  0   0 593   3   4   0]\n",
            " [  0   3   7 590   0   0]\n",
            " [  3   0   0   0 597   0]\n",
            " [  0   5   0   0   0 595]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}